{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da67a37c-7b5a-4bc8-a371-cee8928221de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import dataframe\n",
    "\n",
    "spark = SparkSession.Builder().appName('writrDFtoCSV').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a005db3d-6587-445c-9208-d7b3c8ca1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|  Rohit|\n",
      "|  2|   Ajay|\n",
      "|  3|Nirmala|\n",
      "|  1|    Ram|\n",
      "|  1|   Tika|\n",
      "+---+-------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'Rohit'), (2, 'Ajay'), (3,'Nirmala'), (1,'Ram'), (1, 'Tika')]\n",
    "\n",
    "schema = StructType()\\\n",
    "        .add(field = 'id', data_type = IntegerType(), nullable = True)\\\n",
    "        .add(field = 'name', data_type = StringType(), nullable = True)\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "351b2a79-d431-414e-a3c4-ed029cd62938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(3,'id').write.mode('overwrite').options(header = True, delimiter = '|').csv('data/writeDFtoCSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdd9c391-ea06-4838-886b-685a3f633885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path='data/writeDFtoCSV', header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327835ec-884c-4f40-94e7-756f9e1fc8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1|Rohit|\n",
      "|  2| Ajay|\n",
      "+---+-----+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "928a35e8-591b-48f4-b07e-b4145a5d6c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on property:\n",
      "\n",
      "    Interface for saving the content of the non-streaming :class:`DataFrame` out into external\n",
      "    storage.\n",
      "    \n",
      "    .. versionadded:: 1.4.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrameWriter`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
      "    >>> type(df.write)\n",
      "    <class '...readwriter.DataFrameWriter'>\n",
      "    \n",
      "    Write the DataFrame as a table.\n",
      "    \n",
      "    >>> _ = spark.sql(\"DROP TABLE IF EXISTS tab2\")\n",
      "    >>> df.write.saveAsTable(\"tab2\")\n",
      "    >>> _ = spark.sql(\"DROP TABLE tab2\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataframe.DataFrame.write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7eb17968-7421-4df2-ae00-eb5a932ad69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7da70-193c-4592-8033-c73f3b3d296a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
