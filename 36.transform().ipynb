{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d71180-03f1-4742-ab46-98e13ed9eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 19:35:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import min, max, upper, trim\n",
    "\n",
    "spark = SparkSession.Builder().appName('transform() function on top of dataFrame & for array type--> for Custom Transformation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8590e848-eb2a-4658-81a0-6b21c557be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Rohit|  2000|\n",
      "|  2| Ajay|  3000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Rohit\", 2000),\n",
    "    (2, \"Ajay\", 3000),\n",
    "]\n",
    "\n",
    "schema = ['id', 'name', 'salary']\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b386b39e-deac-48d8-8554-a3b609b6ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToUpper(df):\n",
    "    return df.withColumn('name', upper(df.name))\n",
    "\n",
    "def doubleTheSalary(df):\n",
    "    return df.withColumn('salary', df.salary * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5959ae-b2f6-440c-9971-32f1d1847dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|ROHIT|  4000|\n",
      "|  2| AJAY|  6000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.transform(convertToUpper)\\\n",
    "        .transform(doubleTheSalary)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17dd41da-93dd-4dec-9e28-040e3089b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af63b365-461c-4480-9e4c-a53bc744dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------------------------+\n",
      "|id |name     |salary|skills                  |\n",
      "+---+---------+------+------------------------+\n",
      "|1  |Rohit    |2000  |[pyspark, Web Dev, DE]  |\n",
      "|2  |Ajay     |3000  |[pyspark, Analyst, LLMs]|\n",
      "|3  |Dhananjay|5000  |[pyspark, Azure]        |\n",
      "+---+---------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1,'Rohit', 2000, ['pyspark', 'Web Dev','DE']),\n",
    "    (2,'Ajay', 3000, ['pyspark', 'Analyst', 'LLMs']),\n",
    "    (3,'Dhananjay', 5000, ['pyspark', 'Azure']),\n",
    "]\n",
    "schema = ['id', 'name', 'salary', 'skills']\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a7f9274-1954-4168-ab20-5d45eb3dbf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------------------------+\n",
      "|id |name     |salary|skills                  |\n",
      "+---+---------+------+------------------------+\n",
      "|1  |Rohit    |2000  |[PYSPARK, WEB DEV, DE]  |\n",
      "|2  |Ajay     |3000  |[PYSPARK, ANALYST, LLMS]|\n",
      "|3  |Dhananjay|5000  |[PYSPARK, AZURE]        |\n",
      "+---+---------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('id','name','salary', transform('skills', lambda x : upper(x)).alias('skills')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a43210-f19a-4f53-b97b-0e2a1c6e8e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------------------------+------------------------+\n",
      "|id |name     |salary|skills                  |Skills                  |\n",
      "+---+---------+------+------------------------+------------------------+\n",
      "|1  |Rohit    |2000  |[pyspark, Web Dev, DE]  |[PYSPARK, WEB DEV, DE]  |\n",
      "|2  |Ajay     |3000  |[pyspark, Analyst, LLMs]|[PYSPARK, ANALYST, LLMS]|\n",
      "|3  |Dhananjay|5000  |[pyspark, Azure]        |[PYSPARK, AZURE]        |\n",
      "+---+---------+------+------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convertToUpper1(x):\n",
    "    return upper(x)\n",
    "\n",
    "df.select('*', transform('skills', convertToUpper1).alias('Skills')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "593a6fb9-819d-49a0-ab54-a5a7cb4bd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb303604-6d76-458c-b23b-38715fb0901d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
