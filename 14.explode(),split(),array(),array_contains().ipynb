{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e984f98-2c13-4399-b22b-4829e41ad9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed9bb1ec-d3bf-4d4b-994a-16bb2c5e6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.Builder().appName('Array_Functions').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "502b66d7-b32e-4b8e-9a96-1b3bf0681bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------------------------------------------+\n",
      "|id |name     |Skills                                               |\n",
      "+---+---------+-----------------------------------------------------+\n",
      "|1  |Rohit    |[Python, PySpark, SAS, SQL, JavaScript]              |\n",
      "|2  |Ajay     |[Python, Computer Science, Power BI, LangChain, LLMs]|\n",
      "|3  |Dhananjay|[Python, Azure, PySpark, SQL, Hive]                  |\n",
      "+---+---------+-----------------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import explode, array, split, array_contains, col, lit, trim\n",
    "\n",
    "data = [\n",
    "    (1,'Rohit', ['Python','PySpark', 'SAS', 'SQL', 'JavaScript']),\n",
    "    (2,'Ajay', ['Python', 'Computer Science', 'Power BI', 'LangChain', 'LLMs']),\n",
    "    (3,'Dhananjay',['Python', 'Azure', 'PySpark', 'SQL', 'Hive'])\n",
    "]\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name = 'id', dataType = IntegerType()),\n",
    "        StructField(name = 'name', dataType = StringType()),\n",
    "        StructField(name = 'Skills', dataType = ArrayType(StringType()))\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.show(truncate = False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c801f31-488c-434a-ac03-d40aaaf9110b",
   "metadata": {},
   "source": [
    "##### explode() function --> To create new row for each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "643ab984-db2f-4fe1-8835-9b5b0ac18390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+\n",
      "| id|     name|     explodedCol|\n",
      "+---+---------+----------------+\n",
      "|  1|    Rohit|          Python|\n",
      "|  1|    Rohit|         PySpark|\n",
      "|  1|    Rohit|             SAS|\n",
      "|  1|    Rohit|             SQL|\n",
      "|  1|    Rohit|      JavaScript|\n",
      "|  2|     Ajay|          Python|\n",
      "|  2|     Ajay|Computer Science|\n",
      "|  2|     Ajay|        Power BI|\n",
      "|  2|     Ajay|       LangChain|\n",
      "|  2|     Ajay|            LLMs|\n",
      "|  3|Dhananjay|          Python|\n",
      "|  3|Dhananjay|           Azure|\n",
      "|  3|Dhananjay|         PySpark|\n",
      "|  3|Dhananjay|             SQL|\n",
      "|  3|Dhananjay|            Hive|\n",
      "+---+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('explodedCol', explode('Skills')).select(['id','name','explodedCol']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca43810e-bc60-4925-a9ed-4df77fcd57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------------------------------------+\n",
      "|id |name     |Skills                                         |\n",
      "+---+---------+-----------------------------------------------+\n",
      "|1  |Rohit    |Python,PySpark,SAS,SQL,JavaScript              |\n",
      "|2  |Ajay     |Python,Computer Science,Power BI,LangChain,LLMs|\n",
      "|3  |Dhananjay|Python,Azure,PySpark,SQL,Hive                  |\n",
      "+---+---------+-----------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Skills: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1,'Rohit', \"Python,PySpark,SAS,SQL,JavaScript\"),\n",
    "    (2,'Ajay', \"Python,Computer Science,Power BI,LangChain,LLMs\"),\n",
    "    (3,'Dhananjay',\"Python,Azure,PySpark,SQL,Hive\")\n",
    "]\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name = 'id', dataType = IntegerType()),\n",
    "        StructField(name = 'name', dataType = StringType()),\n",
    "        StructField(name = 'Skills', dataType = StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.show(truncate = False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e8e41-8eb9-4e1c-bc63-924ad2d1c336",
   "metadata": {},
   "source": [
    "##### split() function --> Split the string to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f00158d9-e93a-4943-bbc8-14f2f174d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+\n",
      "| id|     name|              Skills|         skillsArray|\n",
      "+---+---------+--------------------+--------------------+\n",
      "|  1|    Rohit|Python,PySpark,SA...|[Python, PySpark,...|\n",
      "|  2|     Ajay|Python,Computer S...|[Python, Computer...|\n",
      "|  3|Dhananjay|Python,Azure,PySp...|[Python, Azure, P...|\n",
      "+---+---------+--------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Skills: string (nullable = true)\n",
      " |-- skillsArray: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('skillsArray', split(col('skills'),','))\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1410b-b5aa-4342-a8f4-a6199bb8249d",
   "metadata": {},
   "source": [
    "##### array() function --> Create an array column from multiple column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69a1bcbf-fc10-4e12-871d-633a753a9c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------\n",
      " id          | 1                                                       \n",
      " name        | Rohit                                                   \n",
      " Skills      | Python,PySpark,SAS,SQL,JavaScript                       \n",
      " skillsArray | [Python, PySpark, SAS, SQL, JavaScript]                 \n",
      " name_skills | [Rohit, Python,PySpark,SAS,SQL,JavaScript]              \n",
      "-RECORD 1--------------------------------------------------------------\n",
      " id          | 2                                                       \n",
      " name        | Ajay                                                    \n",
      " Skills      | Python,Computer Science,Power BI,LangChain,LLMs         \n",
      " skillsArray | [Python, Computer Science, Power BI, LangChain, LLMs]   \n",
      " name_skills | [Ajay, Python,Computer Science,Power BI,LangChain,LLMs] \n",
      "-RECORD 2--------------------------------------------------------------\n",
      " id          | 3                                                       \n",
      " name        | Dhananjay                                               \n",
      " Skills      | Python,Azure,PySpark,SQL,Hive                           \n",
      " skillsArray | [Python, Azure, PySpark, SQL, Hive]                     \n",
      " name_skills | [Dhananjay, Python,Azure,PySpark,SQL,Hive]              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('name_skills', array('name', 'skills')).show(vertical = True, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0ad1e-ad36-4ed0-ab16-bb5313eded1c",
   "metadata": {},
   "source": [
    "##### array_contains() function --> To check if array contains a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5e640c3-09fa-4c69-9fe6-900ddd07fdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------------------------------------+-----------------------------------------------------+\n",
      "|id |name     |Skills                                         |skillsArray                                          |\n",
      "+---+---------+-----------------------------------------------+-----------------------------------------------------+\n",
      "|1  |Rohit    |Python,PySpark,SAS,SQL,JavaScript              |[Python, PySpark, SAS, SQL, JavaScript]              |\n",
      "|2  |Ajay     |Python,Computer Science,Power BI,LangChain,LLMs|[Python, Computer Science, Power BI, LangChain, LLMs]|\n",
      "|3  |Dhananjay|NULL                                           |NULL                                                 |\n",
      "+---+---------+-----------------------------------------------+-----------------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Skills: string (nullable = true)\n",
      " |-- skillsArray: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1,'Rohit', \"Python,PySpark,SAS,SQL,JavaScript\"),\n",
    "    (2,'Ajay', \"Python,Computer Science,Power BI,LangChain,LLMs\"),\n",
    "    (3,'Dhananjay',None)\n",
    "]\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name = 'id', dataType = IntegerType()),\n",
    "        StructField(name = 'name', dataType = StringType()),\n",
    "        StructField(name = 'Skills', dataType = StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df = df.withColumn('skillsArray', split(col('skills'),','))\n",
    "df.show(truncate = False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39d812cb-ccf2-4436-967e-333bb38f348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+--------------+\n",
      "| id|     name|              Skills|         skillsArray|HasPythonSkill|\n",
      "+---+---------+--------------------+--------------------+--------------+\n",
      "|  1|    Rohit|Python,PySpark,SA...|[Python, PySpark,...|          true|\n",
      "|  2|     Ajay|Python,Computer S...|[Python, Computer...|          true|\n",
      "|  3|Dhananjay|                NULL|                NULL|          NULL|\n",
      "+---+---------+--------------------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('HasPythonSkill', array_contains('skillsArray', 'Python')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10d61959-e261-4099-b4b1-f59036569157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+-----------+\n",
      "| id|     name|              Skills|         skillsArray|HasLLMSkill|\n",
      "+---+---------+--------------------+--------------------+-----------+\n",
      "|  1|    Rohit|Python,PySpark,SA...|[Python, PySpark,...|      false|\n",
      "|  2|     Ajay|Python,Computer S...|[Python, Computer...|       true|\n",
      "|  3|Dhananjay|                NULL|                NULL|       NULL|\n",
      "+---+---------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('HasLLMSkill', array_contains('skillsArray', 'LLMs')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2af0f8fa-3e83-4a55-926b-0b577f7aa302",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153df16-7f60-4843-b2aa-d7e65a1e00e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
